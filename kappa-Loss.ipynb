{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "kappa",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNcvoU5stqIjRuye9XnRHlA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Machine-Learning-rc/Notebooks/blob/master/kappa-Loss.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ArJASVN4sX5d",
        "colab_type": "text"
      },
      "source": [
        "Kappa Loss\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NgTLu4wAsOdK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.metrics import Metric\n",
        "import tensorflow.keras.backend as K\n",
        "RANDOM_SEED = 3\n",
        "tf.random.set_seed(RANDOM_SEED)\n",
        "tf.keras.backend.set_floatx('float64')\n",
        "\n",
        "@tf.function\n",
        "def cohen_kappa_loss(y_true, y_pred, row_label_vec, col_label_vec, weight_mat,  eps=1e-6, dtype=tf.float64):\n",
        "    labels = tf.matmul(y_true, col_label_vec)\n",
        "    weight = tf.pow(tf.tile(labels, [1, tf.shape(y_true)[1]]) - tf.tile(row_label_vec, [tf.shape(y_true)[0], 1]), 2)\n",
        "    weight /= tf.cast(tf.pow(tf.shape(y_true)[1] - 1, 2), dtype=dtype)\n",
        "    numerator = tf.reduce_sum(weight * y_pred)\n",
        "    \n",
        "    denominator = tf.reduce_sum(\n",
        "        tf.matmul(\n",
        "            tf.reduce_sum(y_true, axis=0, keepdims=True),\n",
        "            tf.matmul(weight_mat, tf.transpose(tf.reduce_sum(y_pred, axis=0, keepdims=True)))\n",
        "        )\n",
        "    )\n",
        "    \n",
        "    denominator /= tf.cast(tf.shape(y_true)[0], dtype=dtype)\n",
        "    \n",
        "    return tf.math.log(numerator / denominator + eps)\n",
        "\n",
        "class CohenKappaLoss(tf.keras.losses.Loss):\n",
        "    def __init__(self,\n",
        "                 num_classes,\n",
        "                 name='cohen_kappa_loss',\n",
        "                 eps=1e-6,\n",
        "                 dtype=tf.float64):\n",
        "        super(CohenKappaLoss, self).__init__(name=name, reduction=tf.keras.losses.Reduction.NONE)\n",
        "        \n",
        "        self.num_classes = num_classes\n",
        "        self.eps = eps\n",
        "        self.dtype = dtype\n",
        "        label_vec = tf.range(num_classes, dtype=dtype)\n",
        "        self.row_label_vec = tf.reshape(label_vec, [1, num_classes])\n",
        "        self.col_label_vec = tf.reshape(label_vec, [num_classes, 1])\n",
        "        self.weight_mat = tf.pow(\n",
        "            tf.tile(self.col_label_vec, [1, num_classes]) - tf.tile(self.row_label_vec, [num_classes, 1]),\n",
        "        2) / tf.cast(tf.pow(num_classes - 1, 2), dtype=dtype)\n",
        "\n",
        "\n",
        "    def call(self, y_true, y_pred, sample_weight=None):\n",
        "        return cohen_kappa_loss(\n",
        "            y_true, y_pred, self.row_label_vec, self.col_label_vec, self.weight_mat, self.eps, self.dtype\n",
        "        )\n",
        "\n",
        "\n",
        "    def get_config(self):\n",
        "        config = {\n",
        "            \"num_classes\": self.num_classes,\n",
        "            \"eps\": self.eps,\n",
        "            \"dtype\": self.dtype\n",
        "        }\n",
        "        base_config = super(CohenKappaLoss, self).get_config()\n",
        "        return dict(list(base_config.items()) + list(config.items()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pxu9K8WBsP8G",
        "colab_type": "text"
      },
      "source": [
        "Kappa Metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pUoK0BlFsR72",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CohenKappa(Metric):\n",
        "    \"\"\"\n",
        "    This metric is copied from TensorFlow Addons\n",
        "    \"\"\"\n",
        "    def __init__(self,\n",
        "                 num_classes,\n",
        "                 name='cohen_kappa',\n",
        "                 weightage=None,\n",
        "                 dtype=tf.float32):\n",
        "        super(CohenKappa, self).__init__(name=name, dtype=dtype)\n",
        "\n",
        "        if weightage not in (None, 'linear', 'quadratic'):\n",
        "            raise ValueError(\"Unknown kappa weighting type.\")\n",
        "        else:\n",
        "            self.weightage = weightage\n",
        "\n",
        "        self.num_classes = num_classes\n",
        "        self.conf_mtx = self.add_weight(\n",
        "            'conf_mtx',\n",
        "            shape=(self.num_classes, self.num_classes),\n",
        "            initializer=tf.keras.initializers.zeros,\n",
        "            dtype=tf.int32)\n",
        "    \n",
        "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
        "        if len(y_true.shape) == 2:\n",
        "            y_true = tf.argmax(y_true, axis=1)\n",
        "        if len(y_pred.shape) == 2:\n",
        "            y_pred = tf.argmax(y_pred, axis=1)\n",
        "        \n",
        "        y_true = tf.cast(y_true, dtype=tf.int32)\n",
        "        y_pred = tf.cast(y_pred, dtype=tf.int32)\n",
        "        \n",
        "        if y_true.shape.as_list() != y_pred.shape.as_list():\n",
        "            raise ValueError(\n",
        "                \"Number of samples in y_true and y_pred are different\")\n",
        "\n",
        "        # compute the new values of the confusion matrix\n",
        "        new_conf_mtx = tf.math.confusion_matrix(\n",
        "            labels=y_true,\n",
        "            predictions=y_pred,\n",
        "            num_classes=self.num_classes,\n",
        "            weights=sample_weight)\n",
        "\n",
        "        # update the values in the original confusion matrix\n",
        "        return self.conf_mtx.assign_add(new_conf_mtx)\n",
        "    \n",
        "    def result(self):\n",
        "        nb_ratings = tf.shape(self.conf_mtx)[0]\n",
        "        weight_mtx = tf.ones([nb_ratings, nb_ratings], dtype=tf.int32)\n",
        "\n",
        "        # 2. Create a weight matrix\n",
        "        if self.weightage is None:\n",
        "            diagonal = tf.zeros([nb_ratings], dtype=tf.int32)\n",
        "            weight_mtx = tf.linalg.set_diag(weight_mtx, diagonal=diagonal)\n",
        "            weight_mtx = tf.cast(weight_mtx, dtype=tf.float32)\n",
        "\n",
        "        else:\n",
        "            weight_mtx += tf.range(nb_ratings, dtype=tf.int32)\n",
        "            weight_mtx = tf.cast(weight_mtx, dtype=tf.float32)\n",
        "\n",
        "            if self.weightage == 'linear':\n",
        "                weight_mtx = tf.abs(weight_mtx - tf.transpose(weight_mtx))\n",
        "            else:\n",
        "                weight_mtx = tf.pow((weight_mtx - tf.transpose(weight_mtx)), 2)\n",
        "            weight_mtx = tf.cast(weight_mtx, dtype=tf.float32)\n",
        "\n",
        "        # 3. Get counts\n",
        "        actual_ratings_hist = tf.reduce_sum(self.conf_mtx, axis=1)\n",
        "        pred_ratings_hist = tf.reduce_sum(self.conf_mtx, axis=0)\n",
        "\n",
        "        # 4. Get the outer product\n",
        "        out_prod = pred_ratings_hist[..., None] * \\\n",
        "                    actual_ratings_hist[None, ...]\n",
        "\n",
        "        # 5. Normalize the confusion matrix and outer product\n",
        "        conf_mtx = self.conf_mtx / tf.reduce_sum(self.conf_mtx)\n",
        "        out_prod = out_prod / tf.reduce_sum(out_prod)\n",
        "\n",
        "        conf_mtx = tf.cast(conf_mtx, dtype=tf.float32)\n",
        "        out_prod = tf.cast(out_prod, dtype=tf.float32)\n",
        "\n",
        "        # 6. Calculate Kappa score\n",
        "        numerator = tf.reduce_sum(conf_mtx * weight_mtx)\n",
        "        denominator = tf.reduce_sum(out_prod * weight_mtx)\n",
        "        kp = 1 - (numerator / denominator)\n",
        "        return kp\n",
        "    \n",
        "    def get_config(self):\n",
        "        \"\"\"Returns the serializable config of the metric.\"\"\"\n",
        "\n",
        "        config = {\n",
        "            \"num_classes\": self.num_classes,\n",
        "            \"weightage\": self.weightage,\n",
        "        }\n",
        "        base_config = super(CohenKappa, self).get_config()\n",
        "        return dict(list(base_config.items()) + list(config.items()))\n",
        "\n",
        "    def reset_states(self):\n",
        "        \"\"\"Resets all of the metric state variables.\"\"\"\n",
        "\n",
        "        for v in self.variables:\n",
        "            K.set_value(\n",
        "                v, np.zeros((self.num_classes, self.num_classes), np.int32))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QHcgxijzsxZl",
        "colab_type": "text"
      },
      "source": [
        "How to use it:\n",
        " \n",
        " First define the model\n",
        " Then\n",
        "\n",
        "    val_kappas = []\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=tf.keras.optimizers.Nadam(),\n",
        "        loss=CohenKappaLoss(4),\n",
        "        metrics=[CohenKappa(num_classes=4, weightage='quadratic')]\n",
        "    )\n",
        "\n",
        "    model.fit(train_set_, epochs=num_epoch, verbose=2)\n",
        "    loss, kappa = model.evaluate(val_set_, verbose=2)\n",
        "    val_kappas.append(kappa)\n",
        "    print(f'validation result, loss: {loss}, kappa: {kappa}')\n",
        "\n",
        "    test_preds += model.predict(test_set_)\n",
        "    print(f'validation mean: {np.mean(val_kappas)}, std: {np.std(val_kappas)}')\n",
        "\n",
        "For more info:https://www.kaggle.com/wuwenmin/dnn-and-effective-soft-quadratic-kappa-loss#Kappa-Loss-and-Kappa-Metric"
      ]
    }
  ]
}